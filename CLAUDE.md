# ğŸ“‹ SEDO TSS Converter

## ğŸ¯ Má»¥c tiÃªu
Chuyá»ƒn Ä‘á»•i file Excel compliance test summary tá»« format Input (phá»©c táº¡p, nhiá»u merged cells) sang format Output (structured, database-ready).

**Key principle: ADAPTIVE, not HARDCODED!** ğŸ”‘

## âœ… TrÆ°á»›c khi báº¯t Ä‘áº§u

### Kiá»ƒm tra file input
```bash
# BÆ°á»›c 1: Kiá»ƒm tra file trÆ°á»›c khi cháº¡y pipeline
python validate_my_file.py "data/input/your-file.xlsx"

# BÆ°á»›c 2: Chá»‰ tiáº¿p tá»¥c náº¿u validation PASSED
```

**ğŸ“‹ TÃ i liá»‡u há»— trá»£:**
- `INPUT_REQUIREMENTS.md` - YÃªu cáº§u chi tiáº¿t file input
- `QUICK_CHECKLIST.md` - Checklist nhanh 5 phÃºt  
- `EMAIL_TEMPLATE.md` - Template gá»­i cho users
- `pipeline_validator.py` - Comprehensive validation tool

## ğŸš€ Sá»­ dá»¥ng nhanh

### ğŸ¯ **Centralized Pipeline Execution** (Recommended)
```python
# Using centralized pipeline runner - Single Point of Truth
from pipeline_runner import run_complete_pipeline

result = run_complete_pipeline("data/input/input-1.xlsx", verbose=True)
if result.success:
    print(f"âœ… Pipeline completed: {result.final_output}")
else:
    print(f"âŒ Pipeline failed: {result.error}")
```

### ğŸ”„ **Web Interface** (Streamlit)
```bash
# Launch web interface - uses centralized configuration automatically
streamlit run app.py
```
- **Features**: Drag & drop upload, real-time progress, automatic pipeline execution
- **Sync**: Automatically reflects any pipeline updates from centralized config

### âš™ï¸ **Individual CLI Steps** (Manual/Advanced)
```bash
# Complete pipeline: Input â†’ Output final (manual execution)
python step1_unmerge_standalone.py data/input/input-1.xlsx
python step2_header_processing.py data/output/output-1-Step1.xlsx  
python step3_template_creation.py data/output/output-1-Step2.xlsx
python step4_article_filling.py data/input/input-1.xlsx data/output/output-1-Step3.xlsx
python step5_data_transformation.py data/output/output-1-Step2.xlsx data/output/output-1-Step4.xlsx
python step6_sd_processing.py data/output/output-1-Step2.xlsx --step4-file data/output/output-1-Step5.xlsx
python step7_finished_product.py data/input/input-1.xlsx --step6-file data/output/output-1-Step6.xlsx
python step8_document_processing.py data/input/input-1.xlsx --step7-file data/output/output-1-Step7.xlsx
```

### ğŸ”§ **Single Step Execution**
```bash
# Example: Cháº¡y riÃªng Step 1
python step1_unmerge_standalone.py data/input/input-1.xlsx -v

# Example: Cháº¡y riÃªng Step 8 (final output)  
python step8_document_processing.py data/input/input-1.xlsx --step7-file data/output/output-1-Step7.xlsx
```

## ğŸ“ Cáº¥u trÃºc project

```
/
â”œâ”€â”€ ğŸ¯ CENTRALIZED CONFIGURATION (Single Point of Truth)
â”‚   â”œâ”€â”€ pipeline_config.py               # Step definitions, metadata, dependencies
â”‚   â”œâ”€â”€ pipeline_runner.py               # Unified execution engine for all interfaces
â”‚   â””â”€â”€ app.py                          # Streamlit web interface (auto-synced)
â”‚
â”œâ”€â”€ ğŸ” VALIDATION SYSTEM
â”‚   â”œâ”€â”€ validate_my_file.py              # User-friendly file validator
â”‚   â”œâ”€â”€ pipeline_validator.py            # Comprehensive pre-flight validation
â”‚   â””â”€â”€ validation_utils.py              # Core validation utilities & error handling
â”‚
â”œâ”€â”€ ğŸ”„ PROCESSING PIPELINE (8 steps)
â”‚   â”œâ”€â”€ step1_unmerge_standalone.py      # Step 1: Unmerge cells
â”‚   â”œâ”€â”€ step2_header_processing.py       # Step 2: Process headers  
â”‚   â”œâ”€â”€ step3_template_creation.py       # Step 3: Create template
â”‚   â”œâ”€â”€ step4_article_filling.py         # Step 4: Fill article info
â”‚   â”œâ”€â”€ step5_data_transformation.py     # Step 5: Transform data  
â”‚   â”œâ”€â”€ step6_sd_processing.py           # Step 6: SD processing & de-duplication
â”‚   â”œâ”€â”€ step7_finished_product.py        # Step 7: Article matching & validation
â”‚   â””â”€â”€ step8_document_processing.py     # Step 8: Final document processing
â”‚
â”œâ”€â”€ ğŸ“‹ DOCUMENTATION
â”‚   â”œâ”€â”€ INPUT_REQUIREMENTS.md            # Detailed file requirements
â”‚   â”œâ”€â”€ QUICK_CHECKLIST.md              # 5-minute validation checklist
â”‚   â”œâ”€â”€ EMAIL_TEMPLATE.md               # Template for users
â”‚   â””â”€â”€ CLAUDE.md                       # This file - developer guide
â”‚
â”œâ”€â”€ ğŸ“¦ DEPENDENCIES
â”‚   â””â”€â”€ requirements.txt                 # Python dependencies
â”‚
â””â”€â”€ ğŸ“Š DATA
    â”œâ”€â”€ input/                          # Input files (Input-X.xlsx)
    â””â”€â”€ output/                         # All outputs (Step1â†’Step8)
```

## ğŸ”„ Pipeline Logic - 8 Steps Complete

### ğŸ” **Pre-validation**
```bash
python validate_my_file.py "input.xlsx"  # ALWAYS run first!
```
- **Purpose**: Prevent pipeline failures by validating upfront
- **Checks**: File format, size, structure, required headers
- **Output**: PASS/FAIL with actionable error messages

### **Step 1: Unmerge Cells** ğŸ“Š
```bash
python step1_unmerge_standalone.py data/input/input-X.xlsx
```
- **Input**: `data/input/Input-X.xlsx` (raw file with merged cells)
- **Output**: `data/output/output-X-Step1.xlsx`
- **Logic**: 
  - Detect all merged cell ranges
  - Preserve top-left cell values
  - Unmerge all ranges and fill empty cells
  - **Key**: Foundation step - makes data accessible

### **Step 2: Header Processing** ğŸ¯
```bash
python step2_header_processing.py data/output/output-X-Step1.xlsx
```
- **Input**: `data/output/output-X-Step1.xlsx`
- **Output**: `data/output/output-X-Step2.xlsx`
- **Logic**: Find "General Type/Sub-Type in Connect" header â†’ Process 3 rows below with 3-case logic:
  - **Case 1**: `val16==val17==val18` â†’ empty, keep val17, empty
  - **Case 2**: `val16!=val17==val18` â†’ keep val16, keep val17, empty  
  - **Case 3**: `val16!=val17!=val18` â†’ keep val16, val17+" "+val18, empty

### **Step 3: Template Creation** ğŸ“‹
```bash
python step3_template_creation.py data/output/output-X-Step2.xlsx
```
- **Input**: `data/output/output-X-Step2.xlsx`
- **Output**: `data/output/output-X-Step3.xlsx`
- **Logic**:
  - Create structured template with 17 standardized headers
  - Apply professional formatting (borders, colors, fonts)
  - Set column widths and cell alignment
  - **Purpose**: Clean, database-ready structure

### **Step 4: Article Filling** ğŸ·ï¸
```bash
python step4_article_filling.py data/input/input-X.xlsx data/output/output-X-Step3.xlsx
```
- **Input**: Original input + Step3 template
- **Output**: `data/output/output-X-Step4.xlsx`
- **Logic**:
  - **Dynamic header detection**: Find "Article Name"/"Article No." headers (adaptive positioning)
  - **Multi-article extraction**: Extract multiple articles from original file
  - **Professional formatting**: Place in R+ columns, 90Â° rotation, orange background
  - **Boundary detection**: Only search above "General Type" header

### **Step 5: Data Transformation** ğŸ”„
```bash
python step5_data_transformation.py data/output/output-X-Step2.xlsx data/output/output-X-Step4.xlsx
```
- **Input**: Step2 data + Step4 template
- **Output**: `data/output/output-X-Step5.xlsx`
- **Logic**:
  - **Intelligent mapping**: Map Step2 data â†’ Step4 template structure
  - **Data preservation**: Ensure no information loss during transformation
  - **Format consistency**: Maintain template formatting while adding data

### **Step 6: SD Processing** ğŸ”§
```bash
python step6_sd_processing.py data/output/output-X-Step2.xlsx --step4-file data/output/output-X-Step5.xlsx
```
- **Input**: Step2 + Step5
- **Output**: `data/output/output-X-Step6.xlsx`
- **Logic**:
  - **Hâ†’P column mapping**: Map H values to corresponding P column
  - **Multi-line parsing**: Handle complex SD data with line breaks
  - **Smart de-duplication**: Remove duplicates while preserving unique entries
  - **Data validation**: Ensure SD data integrity

### **Step 7: Finished Product Validation** âœ…
```bash
python step7_finished_product.py data/input/input-X.xlsx --step6-file data/output/output-X-Step6.xlsx
```
- **Input**: Original input + Step6
- **Output**: `data/output/output-X-Step7.xlsx`
- **Logic**:
  - **Article matching**: Match finished products with article definitions
  - **Fuzzy matching**: Handle variations in article names (case, spacing)
  - **"All items" logic**: If P contains "All"/"All items"/"All products" â†’ mark all articles
  - **Validation rules**: Ensure product-article consistency

### **Step 8: Document Processing** ğŸ“„
```bash
python step8_document_processing.py data/input/input-X.xlsx --step7-file data/output/output-X-Step7.xlsx
```
- **Input**: Original input + Step7
- **Output**: `data/output/output-X-Step8.xlsx` âœ… **FINAL RESULT**
- **Logic**:
  - **Requirement source extraction**: Parse complex requirement patterns (IOS, MAT, EN, etc.)
  - **Advanced pattern matching**: Handle separators (&, ,, ;) and nested requirements
  - **Document validation**: Ensure all requirements properly categorized
  - **Final quality check**: Comprehensive output validation

## ğŸ¯ Success Criteria

Pipeline Ä‘Æ°á»£c coi lÃ  thÃ nh cÃ´ng khi:
1. âœ… **Pre-validation PASSED** - File input Ä‘Ãºng format vÃ  structure
2. âœ… **All 8 steps execute** - KhÃ´ng cÃ³ step nÃ o fail
3. âœ… **Data integrity** - KhÃ´ng máº¥t thÃ´ng tin qua cÃ¡c step
4. âœ… **Output quality** - Step8 file Ä‘Ãºng format, Ä‘á»§ data
5. âœ… **Performance** - Xá»­ lÃ½ file 1000 rows trong <10 seconds
6. âœ… **Error handling** - Clear error messages khi cÃ³ issues

## ğŸ”§ Debug & Troubleshooting

### Validation trÆ°á»›c khi cháº¡y
```bash
# ALWAYS validate input first
python validate_my_file.py "data/input/your-file.xlsx" -v

# Advanced validation
python pipeline_validator.py "data/input/your-file.xlsx" -v
```

### Debug tá»«ng step
```bash
# Debug Step 1
python step1_unmerge_standalone.py data/input/input-X.xlsx -v

# Debug Step 2  
python step2_header_processing.py data/output/output-X-Step1.xlsx -v

# Debug Step 8 (final)
python step8_document_processing.py data/input/input-X.xlsx --step7-file data/output/output-X-Step7.xlsx -v
```

### Common Issues & Solutions

#### **ğŸš¨ Input Validation Failures**
- **Issue**: `"General Type header not found"`
- **Solution**: Verify "General Type/Sub-Type in Connect" exists in first 50 rows
- **Fix**: Check exact text matching, case insensitive OK

#### **ğŸš¨ Pipeline Step Failures**
- **Step 1**: Merge detection problems â†’ check Excel file structure
- **Step 2**: Header not found â†’ verify "General Type/Sub-Type in Connect" exists  
- **Step 4**: Article headers missing â†’ check "Article Name"/"Article No." headers above "General Type"
- **Step 6**: Over-aggressive de-duplication â†’ check empty columns in Hâ†’P mapping
- **Step 7**: Article matching fails â†’ verify article definitions in original file
- **Step 8**: Pattern extraction errors â†’ check requirement source formatting

#### **ğŸš¨ Performance Issues**
- **Large files (>50MB)**: Consider splitting into smaller chunks
- **Many merged cells (>1000)**: Step 1 may take longer, normal behavior
- **Complex SD data**: Step 6 processing time increases with data complexity

## ğŸ“Š Test Files

ÄÃ£ test vá»›i cÃ¡c files:
- `Test1.xlsx`: Complete test case with all features
- `input-1.xlsx`: Single article, basic structure
- `input-4.xlsx`: Multiple articles  
- `input-5.xlsx`: DRÃ–NA case study
- `input-6.xlsx`: Different column positions
- `Drona.xlsx`: Real-world example
- `Skubb.xlsx`: Multiple articles (6 articles)
- `frakta.xlsx`: SPARKA series (5 articles)

## ğŸ¯ Key Features

### **ğŸ” Validation System**
- **Pre-flight validation**: Comprehensive file checking before processing
- **Early termination**: Stop on invalid input with clear error messages
- **User guidance**: Detailed requirements documentation and tools

### **ğŸ”§ Processing Pipeline**
- **Adaptive logic**: Dynamic header detection, khÃ´ng hardcode positions
- **Robust unmerging**: Handles complex merged cell patterns
- **Multi-article support**: Extract multiple articles automatically
- **Smart de-duplication**: Intelligent duplicate removal
- **Advanced matching**: Fuzzy article matching with "All items" logic
- **Pattern recognition**: Complex requirement source extraction

### **ğŸ› ï¸ Development Features**
- **Error handling**: Structured ValidationError with actionable messages
- **Standalone tools**: Má»—i step cÃ³ thá»ƒ cháº¡y Ä‘á»™c láº­p
- **Comprehensive logging**: Detailed progress tracking
- **Clean architecture**: Modular, maintainable code structure

---

# ğŸ¯ Centralized Configuration System

## âš¡ Single Point of Truth Architecture

**Starting in version 3.0.0**, the pipeline uses a centralized configuration system that eliminates duplicate code between CLI and Streamlit interfaces.

### ğŸ”§ **Core Components**

#### `pipeline_config.py` - Central Configuration
```python
from pipeline_config import PipelineConfig

# Get all step metadata
steps = PipelineConfig.get_all_steps()
for step in steps:
    print(f"Step {step.step_number}: {step.display_name}")
    print(f"Description: {step.description}")
    print(f"Class: {step.class_name}")

# Get specific step
step1 = PipelineConfig.get_step(1)
print(f"Step 1 module: {step1.module_name}")
```

#### `pipeline_runner.py` - Unified Execution
```python
from pipeline_runner import PipelineRunner, run_complete_pipeline

# Quick execution
result = run_complete_pipeline("input.xlsx", verbose=True)

# Advanced execution with progress tracking
def progress_callback(progress, current, total, status):
    print(f"Progress: {progress*100:.1f}% - {status}")

runner = PipelineRunner(base_dir=".", verbose=True)
result = runner.run_pipeline(
    input_file="input.xlsx",
    progress_callback=progress_callback
)
```

### ğŸ”„ **Automatic Synchronization**

**Before (Manual Maintenance)**:
- Update step names in `app.py` hardcoded list âŒ
- Update CLI help text in each step file âŒ 
- Manually sync descriptions between interfaces âŒ
- Risk of inconsistency between CLI and Web âŒ

**After (Centralized Configuration)**:
- Update step metadata in `pipeline_config.py` ONCE âœ…
- CLI and Streamlit automatically sync âœ…
- Consistent naming and descriptions âœ…
- Single source of truth for all interfaces âœ…

### ğŸš€ **Benefits Achieved**

1. **ğŸ¯ Single Source of Truth**: All pipeline metadata in `pipeline_config.py`
2. **ğŸ”„ Automatic Updates**: Changes propagate to both CLI and web interface
3. **ğŸ› ï¸ Easier Maintenance**: Add/modify/remove steps in one location
4. **ğŸ“Š Consistent Experience**: Same step names, descriptions across all interfaces
5. **ğŸ§ª Better Testing**: Centralized validation of step dependencies
6. **ğŸ“ˆ Future-Proof**: Easy to add new execution modes (API, desktop app, etc.)

### ğŸ”§ **Making Changes to Pipeline**

#### Adding a New Step (Example: Step 9)
```python
# 1. Add to pipeline_config.py
StepMetadata(
    step_number=9,
    name="optimize_output",
    display_name="Optimizing final output", 
    description="Apply final optimizations and quality checks",
    class_name="OutputOptimizer",
    module_name="step9_output_optimization",
    depends_on=[8],
    cli_script="step9_output_optimization.py",
    estimated_duration_seconds=5
)

# 2. Create step9_output_optimization.py with standard interface
class OutputOptimizer:
    @classmethod
    def get_metadata(cls):
        return PipelineConfig.get_step(9)
    
    def optimize_output(self, input_file, output_file=None):
        # Implementation here
        pass

# 3. Done! CLI and Streamlit automatically include Step 9
```

#### Modifying Step Names/Descriptions
```python
# Edit pipeline_config.py - changes apply everywhere
StepMetadata(
    step_number=1,
    display_name="Unmerging merged cells",  # â† Changed here
    description="New description here",      # â† Changed here
    # ... rest unchanged
)
# Streamlit and CLI automatically reflect changes
```

### ğŸ“‹ **Migration Completed**

| Component | Status | Changes Made |
|-----------|--------|--------------|
| `pipeline_config.py` | âœ… **NEW** | Central step definitions and metadata |
| `pipeline_runner.py` | âœ… **NEW** | Unified execution engine |
| `app.py` | âœ… **UPDATED** | Uses centralized pipeline runner |
| `step1-8.py` | âœ… **UPDATED** | Added metadata methods |
| CLI compatibility | âœ… **MAINTAINED** | Full backward compatibility |
| Documentation | âœ… **UPDATED** | Reflects centralized approach |

---

# ğŸ‘¨â€ğŸ’» Developer Guide

## ğŸ—ï¸ Architecture Overview

### **Validation Layer**
```python
validation_utils.py       # Core validation classes & utilities
â”œâ”€â”€ ValidationError      # Structured error handling
â”œâ”€â”€ FileValidator       # Excel file validation  
â”œâ”€â”€ HeaderDetector      # Dynamic header detection
â””â”€â”€ ErrorHandler        # User-friendly error messages

pipeline_validator.py    # Comprehensive pre-flight validation
â””â”€â”€ PipelineValidator   # Multi-stage validation workflow
```

### **Processing Layer**
```
step1_unmerge_standalone.py    â†’ ExcelUnmerger
step2_header_processing.py     â†’ HeaderProcessor  
step3_template_creation.py     â†’ TemplateCreator
step4_article_filling.py       â†’ ArticleFiller
step5_data_transformation.py   â†’ DataTransformer
step6_sd_processing.py         â†’ SDProcessor
step7_finished_product.py      â†’ FinishedProductProcessor
step8_document_processing.py   â†’ DocumentProcessor
```

### **User Interface Layer**
```
validate_my_file.py           # User-friendly validation script
INPUT_REQUIREMENTS.md         # Detailed requirements
QUICK_CHECKLIST.md           # Quick reference
EMAIL_TEMPLATE.md            # Communication template
```

## ğŸ”§ Adding New Features

### **Adding New Validation Rules**
1. **Edit `validation_utils.py`**:
```python
class FileValidator:
    @classmethod
    def validate_new_requirement(cls, file_path: Path) -> bool:
        # Your validation logic here
        pass
```

2. **Update `pipeline_validator.py`**:
```python
def _validate_step_requirements(self, input_path: Path):
    # Add your new validation call
    if not FileValidator.validate_new_requirement(input_path):
        raise ValidationError("Your error message")
```

### **Adding New Processing Step**
1. **Create `step9_your_feature.py`**:
```python
class YourProcessor:
    def process_file(self, input_file, output_file=None):
        # Pre-flight validation
        if not validate_before_pipeline(input_file, verbose=True):
            raise ValidationError("Validation failed")
        
        # Your processing logic
        # ...
        
        return str(output_file)
```

2. **Update CLAUDE.md** vá»›i step má»›i
3. **Add to documentation** vÃ  test files

### **Modifying Header Detection**
Edit `validation_utils.py`:
```python
class HeaderDetector:
    @classmethod
    def find_your_header(cls, worksheet) -> Optional[Tuple[int, int, str]]:
        patterns = ["Your Header Pattern", "Alternative Pattern"]
        return cls.find_header_fuzzy(worksheet, patterns)
```

## ğŸ“¦ Dependencies

```bash
pip install openpyxl  # Excel file processing
```

## ğŸ“‹ Code Principles

### **ğŸš« DON'Ts**
- **NEVER** hardcode column positions (always use dynamic detection)
- **NEVER** assume fixed file structure (use adaptive logic)
- **NEVER** ignore errors (always handle gracefully)
- **NEVER** skip validation (pre-flight check everything)

### **âœ… DOs**
- **ALWAYS** use dynamic header detection  
- **PREFER** adaptive logic over fixed patterns
- **ENSURE** data preservation at every step
- **VALIDATE** inputs before processing
- **PROVIDE** actionable error messages
- **TEST** with real-world files
- **DOCUMENT** logic changes in CLAUDE.md

### **ğŸ”„ Update Workflow**
1. **Modify code** vá»›i new feature/fix
2. **Test thoroughly** vá»›i existing test files
3. **Update CLAUDE.md** vá»›i logic changes
4. **Update documentation** náº¿u cáº§n (INPUT_REQUIREMENTS.md, etc.)
5. **Commit changes** vá»›i clear message
6. **Update version** trong requirements.txt náº¿u cáº§n

---

**ğŸ“ Last Updated**: 2026-01-04  
**ğŸ”§ Version**: 3.0.0 (Centralized configuration with single point of truth)  
**ğŸ‘¨â€ğŸ’» Maintainer**: Check git log for contributors